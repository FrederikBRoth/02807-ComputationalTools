{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfa110bb",
   "metadata": {},
   "source": [
    "# Week 2 - Exercises\n",
    "Exercise 1\n",
    "#\n",
    "[map, filter, reduce documentation](https://www.learnpython.org/en/Map%2C_Filter%2C_Reduce)\n",
    "#\n",
    "This is the map function in python. Map applies a function on all elements in the list and results in a new changed list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb839595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shitty way\n",
    "credit_cards = [913, 113, 513, 173, 645, 654]\n",
    "\n",
    "newlist = []\n",
    "\n",
    "for card in credit_cards:\n",
    "    card_ = card + 1000\n",
    "    newlist.append(card_)\n",
    "\n",
    "print(newlist)\n",
    "\n",
    "# Cool way\n",
    "\n",
    "new_cool = list(map(lambda x: x + 2000, credit_cards))\n",
    "print(new_cool)\n",
    "\n",
    "# You can pass as many arguments as the functions can take\n",
    "\n",
    "new_new_cool = list(map(lambda x, y: x + y + 1000, credit_cards, range(1, 10)))\n",
    "print(new_new_cool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204c777f",
   "metadata": {},
   "source": [
    "Filter function\n",
    "Filter function tldr:\n",
    "1. Unlike map(), only one iterable is required.\n",
    "2. The func argument is required to return a boolean type. If it doesn't, filter simply returns the iterable passed to it. Also, as only one iterable is required, it's implicit that func must only take one argument.\n",
    "3. filter passes each element in the iterable through func and returns only the ones that evaluate to true. I mean, it's right there in the name -- a \"filter\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7a136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "\n",
    "dank_meme = [85, 69, 420, 20, 22]\n",
    "\n",
    "\n",
    "def is_meme(id):\n",
    "    return id == 85 or id == 420 or id == 69\n",
    "\n",
    "\n",
    "real_memes = list(filter(is_meme, dank_meme))\n",
    "print(real_memes)\n",
    "\n",
    "# You can do lambdas aswell\n",
    "\n",
    "dromes = ['bob', 'nothing', 'anutforajaroftuna', 'rewire']\n",
    "\n",
    "test = 'yooo'\n",
    "reversed = test[::-1]\n",
    "print(reversed)\n",
    "\n",
    "# FYI you can do lists like [<start>:<stop>:<step>]\n",
    "palindromes = list(filter(lambda word: word == word[::-1], dromes))\n",
    "print(palindromes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7cd0ed",
   "metadata": {},
   "source": [
    "Reduce function\n",
    "Can take a list and iteratively add the elements together (or somethign else, depending on the function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affd2de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "abc = ['a', 'b', 'c', 'd']\n",
    "together = reduce(lambda a, b: a + b, abc)\n",
    "print(together)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683d99b5",
   "metadata": {},
   "source": [
    "Exercise in map, filter and reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b128afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import numpy as np\n",
    "\n",
    "# Use map to print the square of each numbers rounded\n",
    "# to three decimal places\n",
    "my_floats = [4.35, 6.09, 3.25, 9.77, 2.16, 8.88, 4.59]\n",
    "\n",
    "# Use filter to print only the names that are less than\n",
    "# or equal to seven letters\n",
    "my_names = ['olumide', 'akinremi', 'josiah', 'temidayo', 'omoseun']\n",
    "\n",
    "# Use reduce to print the product of these numbers\n",
    "my_numbers = [4, 6, 9, 23, 5]\n",
    "\n",
    "# Fix all three respectively.\n",
    "map_result = list(map(lambda x: round(np.square(x), 3), my_floats))\n",
    "filter_result = list(filter(lambda name: len(name) <= 7, my_names))\n",
    "reduce_result = reduce(lambda num1, num2: num1 * num2, my_numbers)\n",
    "\n",
    "print(map_result)\n",
    "print(filter_result)\n",
    "print(reduce_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c225bc",
   "metadata": {},
   "source": [
    "# Exercise 2 - Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40daeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My solution\n",
    "import re\n",
    "from functools import reduce\n",
    "\n",
    "document = re.findall(r'\\b\\w+\\b', open('./Data/enchantedForest.txt').read())\n",
    "\n",
    "uniques = list(set(document))\n",
    "\n",
    "freq_of_word = dict.fromkeys(uniques)\n",
    "\n",
    "for key in freq_of_word:\n",
    "    freq_of_word[key] = len(list(filter(lambda word: word == key, document)))\n",
    "\n",
    "# Intended approach\n",
    "document = {\n",
    "    'Document1': re.findall(\n",
    "        r'\\b\\w+\\b', open('./Data/enchantedForest.txt').read()\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "def combine_pairs(acc, pair):\n",
    "    key, value = pair\n",
    "    if not acc:\n",
    "        return [(key, int(value))]\n",
    "\n",
    "    # find the index of the key if it exists in the accumulator\n",
    "    for i, (acc_key, acc_value) in enumerate(acc):\n",
    "        if acc_key == key:\n",
    "            acc[i] = (key, acc_value + int(value))\n",
    "            break\n",
    "    else:\n",
    "        acc.append((key, int(value)))\n",
    "\n",
    "    return acc\n",
    "\n",
    "\n",
    "mapped = list(map(lambda x: (x, 1), document['Document1']))\n",
    "reduced = reduce(combine_pairs, mapped, [])\n",
    "\n",
    "print(reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2735530b",
   "metadata": {},
   "source": [
    "# Exercise 3 - Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e9ce86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from functools import reduce\n",
    "\n",
    "documents = {\n",
    "    1: re.findall(r'\\b\\w+\\b', open('./Data/Story1.txt').read()),\n",
    "    2: re.findall(r'\\b\\w+\\b', open('./Data/Story2.txt').read()),\n",
    "}\n",
    "\n",
    "mapped = []\n",
    "for i in documents.items():\n",
    "    print(i[0])\n",
    "    mapped.extend(list(map(lambda x: (x, i[0]), i[1])))\n",
    "print(mapped)\n",
    "\n",
    "\n",
    "def merge_lists_tupl(acc, pair):\n",
    "    word, doc_id = pair\n",
    "    for i, (existing_word, doc_ids) in enumerate(acc):\n",
    "        if word == existing_word and doc_id not in doc_ids:\n",
    "            acc[i] = (word, doc_ids + [doc_id])\n",
    "            break\n",
    "    else:\n",
    "        acc.append((word, [doc_id]))\n",
    "    return acc\n",
    "\n",
    "\n",
    "reduced_tuple = reduce(merge_lists_tupl, mapped, [])\n",
    "print(reduced_tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a710d620",
   "metadata": {},
   "source": [
    "# Exercise 4 - Euler Tour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f50625c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "init_matrix = np.loadtxt('./Data/eulerGraphs1.txt')\n",
    "graph = np.unique(init_matrix, axis=0).tolist()\n",
    "\n",
    "vertices = list(set(reduce(lambda x, y: x + y, graph)))\n",
    "\n",
    "\n",
    "# For every vertice in vertices check map all occurences in all lists in graph\n",
    "# If it is contained do 1 else 0.\n",
    "# then reduce it to get the total count pr vertices\n",
    "degrees = list(\n",
    "    map(\n",
    "        lambda v: reduce(\n",
    "            lambda x, y: x + y, map(lambda e: 1 if v in e else 0, graph)\n",
    "        ),\n",
    "        vertices,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Count the number of vertices with even and odd degrees\n",
    "even = reduce(\n",
    "    lambda acc, degree: acc + 1 if degree % 2 == 0 else acc, degrees, 0\n",
    ")\n",
    "odd = reduce(\n",
    "    lambda acc, degree: acc + 1 if degree % 2 != 0 else acc, degrees, 0\n",
    ")\n",
    "\n",
    "print(even)\n",
    "print(odd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f3bda2",
   "metadata": {},
   "source": [
    "# Exercise 5 - Common Friends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6849d0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "\n",
    "def split(line):\n",
    "    friend = line.split(':')\n",
    "    friends = list(map(int, friend[1].split(',')))\n",
    "    return (int(friend[0]), friends)\n",
    "\n",
    "\n",
    "lines = list(map(split, open('./Data/friends2.txt').readlines()))\n",
    "mapped = []\n",
    "for i in lines:\n",
    "    mapped.extend(list(map(lambda y: (sorted([i[0], y]), i[1]), i[1])))\n",
    "\n",
    "\n",
    "def merge_lists_tuple(acc, pair):\n",
    "    friend_pair, friends = pair\n",
    "    for i, (existing_pair, existing_friends) in enumerate(acc):\n",
    "        if friend_pair == existing_pair:\n",
    "            acc[i] = (\n",
    "                friend_pair,\n",
    "                list(filter(lambda x: x in existing_friends, friends)),\n",
    "            )\n",
    "            break\n",
    "    else:\n",
    "        acc.append((friend_pair, friends))\n",
    "    return acc\n",
    "\n",
    "\n",
    "reduced = reduce(merge_lists_tuple, mapped, [])\n",
    "print(reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea361ca",
   "metadata": {},
   "source": [
    "# Exercise 6 - Triangle Counting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "488d4c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1965206\n"
     ]
    },
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\nUntyped global name 'neighbors': Cannot determine Numba type of <class 'dict'>\n\nFile \"../../../../../../tmp/ipykernel_3192/3383303925.py\", line 43:\n<source missing, REPL/exec in use?>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# Divide by 3 because each triangle is counted 3 times\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m total_triangles \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of triangles in the graph:\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numba/core/dispatcher.py:468\u001b[0m, in \u001b[0;36m_DispatcherBase._compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    464\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;241m.\u001b[39mrstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThis error may have been caused \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    465\u001b[0m                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby the following argument(s):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00margs_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    466\u001b[0m         e\u001b[38;5;241m.\u001b[39mpatch_message(msg)\n\u001b[0;32m--> 468\u001b[0m     \u001b[43merror_rewrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtyping\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mUnsupportedError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;66;03m# Something unsupported is present in the user code, add help info\u001b[39;00m\n\u001b[1;32m    471\u001b[0m     error_rewrite(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munsupported_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numba/core/dispatcher.py:409\u001b[0m, in \u001b[0;36m_DispatcherBase._compile_for_args.<locals>.error_rewrite\u001b[0;34m(e, issue_type)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\nUntyped global name 'neighbors': Cannot determine Numba type of <class 'dict'>\n\nFile \"../../../../../../tmp/ipykernel_3192/3383303925.py\", line 43:\n<source missing, REPL/exec in use?>\n"
     ]
    }
   ],
   "source": [
    "# Just a stupid non reduce/map version\n",
    "import numpy as np\n",
    "import numba\n",
    "from functools import reduce\n",
    "\n",
    "filename = './Data/roadnet.txt'\n",
    "\n",
    "neighbors = dict()\n",
    "\n",
    "# Read the file and populate the neighbors dictionary\n",
    "with open(filename, 'r') as file:\n",
    "    for line in file:\n",
    "        edge = line.strip().split()\n",
    "        node1, node2 = int(edge[0]), int(edge[1])\n",
    "\n",
    "        # Add nodes to the neighbors dictionary\n",
    "        if node1 not in neighbors:\n",
    "            neighbors[node1] = set()\n",
    "        if node2 not in neighbors:\n",
    "            neighbors[node2] = set()\n",
    "\n",
    "        # Add edges to the neighbors dictionary\n",
    "        neighbors[node1].add(node2)\n",
    "        neighbors[node2].add(node1)\n",
    "print(len(neighbors))\n",
    "# Function to count triangles for a given node\n",
    "def count_triangles_for_node(node, neighbors):\n",
    "    triangle_count = 0\n",
    "    node_neighbors = neighbors[node]\n",
    "\n",
    "    for neighbor1 in node_neighbors:\n",
    "        for neighbor2 in node_neighbors:\n",
    "            if neighbor1 < neighbor2 and neighbor2 in neighbors[neighbor1]:\n",
    "                triangle_count += 1\n",
    "\n",
    "    return triangle_count\n",
    "\n",
    "\n",
    "# Iterate through nodes and count triangles\n",
    "@numba.njit\n",
    "def test():\n",
    "    total_triangles = 0\n",
    "    for node in neighbors:\n",
    "        total_triangles += count_triangles_for_node(node, neighbors)\n",
    "\n",
    "    # Divide by 3 because each triangle is counted 3 times\n",
    "    return total_triangles / 3\n",
    "\n",
    "print('Number of triangles in the graph:', test())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b877b68c",
   "metadata": {},
   "source": [
    "# Exercise 7 - NetworkX\n",
    "This is legit just a faster way to fix to do it with dedicated functions for graph theory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
